{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003f0e17-8168-4d7a-866f-b8fac7fecb28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data\n",
    "TODO: choose probability/multi-hot/cnn embeddings to read<br />\n",
    "TODO: choose good&bad/good&ugly to read<br />\n",
    "TODO: make good&ugly data sizes same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f82ce-726b-4081-8256-8553abb42416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(file_path, colEQ, colE, colQ):\n",
    "    vecEQs = []\n",
    "    vecEs = []\n",
    "    vecQs = []\n",
    "    labels = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            \n",
    "            # str -> ndarray\n",
    "            vecEQ = np.array(eval(row[colEQ]))\n",
    "            \n",
    "            vecE_str = row[colE]\n",
    "            vecE_list = vecE_str.strip('[]').split()\n",
    "            vecE = np.array([float(value) for value in vecE_list])\n",
    "            \n",
    "            vecQ_str = row[colQ]\n",
    "            vecQ_list = vecQ_str.strip('[]').split()\n",
    "            vecQ = np.array([float(value) for value in vecQ_list])\n",
    "            \n",
    "            label = float(row['label'])\n",
    "            \n",
    "            # append\n",
    "            vecEQs.append(vecEQ)\n",
    "            vecEs.append(vecE)\n",
    "            vecQs.append(vecQ)\n",
    "            labels.append(label)\n",
    "    return np.array(vecEQs), np.array(vecEs), np.array(vecQs), np.array(labels)\n",
    "\n",
    "def read_pickle(file_path):\n",
    "    data = pd.read_pickle(file_path)\n",
    "    #display(data)\n",
    "    vecEQs = np.array([np.array((x)) for x in data['predEQ']])\n",
    "    vecEs = np.array([np.array((x)) for x in data['embedE']])\n",
    "    vecQs = np.array([np.array((x)) for x in data['embedQ']])\n",
    "    labels = data['label'].astype(float).values\n",
    "    return vecEQs, vecEs, vecQs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe96567-3de1-4ee0-bb66-ff101c3d6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good data: 2094 , bad data: 1105\n",
      "vecEQs: (2210, 4096) \n",
      "vecEs: (2210, 2048) \n",
      "vecQs: (2210, 2048) \n",
      "labels: (2210,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "'''\n",
    "# read prob.: good_embedding_probEQ.csv, bad_embedding_probEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/model_train/good_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "#vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/model_train/bad_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/ugly_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "'''\n",
    "'''\n",
    "# read multi-hot: good_embedding_predEQ.csv, bad_embedding_predEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/model_train/good_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "#vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/model_train/bad_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/ugly_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "'''\n",
    "\n",
    "\n",
    "# read cnn: good_embedding.pkl, bad_embedding.pkl\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_pickle('../embeddings/CNN(Resnet50)/good_embedding.pkl')\n",
    "#vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_pickle('../embeddings/CNN(Resnet50)/bad_embedding.pkl')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_pickle('../embeddings/CNN(Resnet50)/ugly_embedding.pkl')\n",
    "print(\"good data:\", len(vecEQs_good), \", bad data:\", len(vecEQs_bad))\n",
    "\n",
    "#'''\n",
    "# good 和 ugly 要一樣的資料量\n",
    "sampling = np.random.choice(vecEQs_good.shape[0], vecEQs_bad.shape[0], replace=False)\n",
    "vecEQs_good = vecEQs_good[sampling, :]\n",
    "vecEs_good = vecEs_good[sampling, :]\n",
    "vecQs_good = vecQs_good[sampling, :]\n",
    "labels_good = labels_good[sampling]\n",
    "#'''\n",
    "\n",
    "# 合併 good & bad data, check shape\n",
    "vecEQs = np.concatenate((vecEQs_good, vecEQs_bad), axis=0)\n",
    "vecEs = np.concatenate((vecEs_good, vecEs_bad), axis=0)\n",
    "vecQs = np.concatenate((vecQs_good, vecQs_bad), axis=0)\n",
    "labels = np.concatenate((labels_good, labels_bad), axis=0)\n",
    "\n",
    "print(\"vecEQs:\", vecEQs.shape, \"\\nvecEs:\", vecEs.shape, \"\\nvecQs:\", vecQs.shape, \"\\nlabels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5693a4-912a-46e8-9da6-adfa81f9b587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (6630, 4096) \n",
      "X^: (6630, 4096)\n"
     ]
    }
   ],
   "source": [
    "# X: EQ, E0, 0Q\n",
    "zeros = np.zeros_like(vecEs)\n",
    "x1 = vecEQs\n",
    "x2 = np.hstack((vecEs, zeros))\n",
    "x3 = np.hstack((zeros, vecQs))\n",
    "x123 = np.vstack((x1, x2, x3))\n",
    "\n",
    "# X^: EQ, EQ, EQ\n",
    "y123 = np.vstack((x1, x1, x1))\n",
    "\n",
    "print(\"X:\", x123.shape, \"\\nX^:\", y123.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdef848-34cd-47fc-8d90-87b2cd5dd342",
   "metadata": {
    "tags": []
   },
   "source": [
    "### model\n",
    "TODO: 注意 training 要丟入的 x, x^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432f2484-15cb-4290-a3ea-82e5dd0ac76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4096)]            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 147)               602259    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 98)                14504     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 147)               14553     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4096)              606208    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1237524 (4.72 MB)\n",
      "Trainable params: 1237524 (4.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 196 >> 147 >> 98 >> 147 >> 196\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# given vecEQs\n",
    "input_dim = vecEQs.shape[1]\n",
    "\n",
    "# encoder layer (196 >> 147 >> 98)\n",
    "encoding_dim1 = 147\n",
    "encoding_dim2 = 98\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1, activation='relu')(input_layer)\n",
    "encoded2 = Dense(encoding_dim2, activation='relu')(encoded1)\n",
    "\n",
    "# decoder layer (98 >> 147 >> 196)\n",
    "decoded1 = Dense(encoding_dim1, activation='relu')(encoded2)\n",
    "decoded2 = Dense(input_dim, activation='sigmoid')(decoded1)\n",
    "\n",
    "# encoder-decoder(196 >> 147 >> 98 >> 147 >> 196)\n",
    "autoencoder = Model(input_layer, decoded2)\n",
    "\n",
    "# encoder model\n",
    "encoder = Model(input_layer, encoded2)\n",
    "\n",
    "# decoder model\n",
    "encoded_input = Input(shape=(encoding_dim2,))\n",
    "decoder_layer1 = autoencoder.layers[-2]\n",
    "decoder_layer2 = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer2(decoder_layer1(encoded_input)))\n",
    "\n",
    "# compile model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c8e00c1-b01e-4f7d-be0d-1243d2452eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0333\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0318 - val_loss: 0.0328\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0311 - val_loss: 0.0328\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0308 - val_loss: 0.0326\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0324\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0303 - val_loss: 0.0324\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0298 - val_loss: 0.0323\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0293 - val_loss: 0.0317\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0287 - val_loss: 0.0307\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0283 - val_loss: 0.0303\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0279 - val_loss: 0.0301\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0275 - val_loss: 0.0297\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0270 - val_loss: 0.0292\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0264 - val_loss: 0.0288\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0256 - val_loss: 0.0283\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0247 - val_loss: 0.0274\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0238 - val_loss: 0.0269\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0232 - val_loss: 0.0268\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0228 - val_loss: 0.0265\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0225 - val_loss: 0.0263\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0223 - val_loss: 0.0263\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0220 - val_loss: 0.0261\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0219 - val_loss: 0.0258\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0217 - val_loss: 0.0257\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0212 - val_loss: 0.0255\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0210 - val_loss: 0.0253\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0208 - val_loss: 0.0253\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0207 - val_loss: 0.0252\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0206 - val_loss: 0.0251\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0205 - val_loss: 0.0252\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0205 - val_loss: 0.0250\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0204 - val_loss: 0.0251\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0203 - val_loss: 0.0250\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0202 - val_loss: 0.0250\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0201 - val_loss: 0.0248\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0200 - val_loss: 0.0249\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0200 - val_loss: 0.0248\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0199 - val_loss: 0.0248\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0198 - val_loss: 0.0246\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0197 - val_loss: 0.0248\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0197 - val_loss: 0.0248\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0196 - val_loss: 0.0246\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0195 - val_loss: 0.0246\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0195 - val_loss: 0.0247\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0193 - val_loss: 0.0246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a75f62310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "#autoencoder.fit(vecEQs, vecEQs, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n",
    "autoencoder.fit(x123, y123, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4413938e-a84a-48e1-8cef-9d531c9964fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# middle layer\n",
    "middle_vecEQs = encoder.predict(vecEQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30467eb4-c5a2-4bcb-9027-d83cbfec344c",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa3894a-2c7c-4af1-9b5b-112c195aabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM] MSE = 0.06797418337624203, MAE = 0.19813784304245097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(middle_vecEQs, labels, test_size=0.2, random_state=42, stratify = labels)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE, MAE\n",
    "y_pred = svm_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[SVM] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d863ec-cdff-4fec-9e0d-9f3f35292d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] MSE = 0.08457398190045248, MAE = 0.21418552036199096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[RF] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3017775f-0c99-4a75-ae9f-ba8a64e4f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 5ms/step - loss: 0.2652 - val_loss: 0.1737\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1000\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.0936 - val_loss: 0.0710\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0645\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0610\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0744\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0559\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0581\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0577\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0585\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0535\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0527\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0538\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0568\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0525\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0573\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0516\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0533\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0541\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0566\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "[NN] MSE = 0.05373021987323608, MAE = 0.1225681022753543\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural Network model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(16, activation='sigmoid'))\n",
    "nn_model.add(Dense(1))  # output layer\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# training\n",
    "nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# MSE\n",
    "y_pred = nn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[NN] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdf5c9-4c6f-4441-9854-d3f9ef63f9c7",
   "metadata": {},
   "source": [
    "### 手動 record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3128d44a-e096-4f38-a690-9f6d6173f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料集(EQ)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.275706</td>\n",
       "      <td>0.311330</td>\n",
       "      <td>0.254638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.258973</td>\n",
       "      <td>0.268861</td>\n",
       "      <td>0.238933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.247601</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.242192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.275706   0.311330  0.254638\n",
       "rf      0.258973   0.268861  0.238933\n",
       "nn      0.247601   0.252473  0.242192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "三倍資料集(EQ, E0, 0Q)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.283773</td>\n",
       "      <td>0.318831</td>\n",
       "      <td>0.233024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.261314</td>\n",
       "      <td>0.236585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.248409</td>\n",
       "      <td>0.256502</td>\n",
       "      <td>0.243901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.283773   0.318831  0.233024\n",
       "rf      0.261029   0.261314  0.236585\n",
       "nn      0.248409   0.256502  0.243901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'probability': [0.2757061123247706, 0.2589729116945107, 0.24760135830766278],\n",
    "    'multi-hot': [0.3113301803055666, 0.26886112194829226, 0.2524728533771422],\n",
    "    'cnn': [0.25463821738103376, 0.23893257756563246, 0.24219229685222451]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=['svm', 'rf', 'nn'])\n",
    "print(\"原始資料集(EQ)\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "data2 = {\n",
    "    'probability': [0.2837730806873752, 0.2610291169451074, 0.2484090777202349],\n",
    "    'multi-hot': [0.3188305040862045, 0.2613142604766219, 0.2565020791026134],\n",
    "    'cnn': [0.23302369784904192, 0.2365852028639618, 0.24390136605141902]\n",
    "}\n",
    "\n",
    "print(\"\\n三倍資料集(EQ, E0, 0Q)\")\n",
    "df2 = pd.DataFrame(data2, index=['svm', 'rf', 'nn'])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717c57a5-8758-44b0-ac47-6f0ee197ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料集(EQ)-good&ugly\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.186688</td>\n",
       "      <td>0.161856</td>\n",
       "      <td>0.083110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.091753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.085786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.186688   0.161856  0.083110\n",
       "rf      0.171692   0.165055  0.091753\n",
       "nn      0.215720   0.170543  0.085786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "三倍資料集(EQ, E0, 0Q)-good&ugly\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.178743</td>\n",
       "      <td>0.174589</td>\n",
       "      <td>0.067974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.170461</td>\n",
       "      <td>0.169308</td>\n",
       "      <td>0.084574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.189689</td>\n",
       "      <td>0.174498</td>\n",
       "      <td>0.053730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.178743   0.174589  0.067974\n",
       "rf      0.170461   0.169308  0.084574\n",
       "nn      0.189689   0.174498  0.053730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# good & ugly\n",
    "\n",
    "data3 = {\n",
    "    'probability': [0.18668784933360047, 0.1716918552036199, 0.21571981347398259],\n",
    "    'multi-hot': [0.16185558967853397, 0.16505469043740614, 0.1705426461395002],\n",
    "    'cnn': [0.08310994265107106, 0.09175294117647059, 0.08578550574683298]\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(data3, index=['svm', 'rf', 'nn'])\n",
    "print(\"原始資料集(EQ)-good&ugly\")\n",
    "display(df3)\n",
    "\n",
    "\n",
    "data4 = {\n",
    "    'probability': [0.17874345017228893, 0.17046108597285067, 0.18968940847495594],\n",
    "    'multi-hot': [0.17458910925342705, 0.1693084523924, 0.17449791095236505],\n",
    "    'cnn': [0.06797418337624203, 0.08457398190045248, 0.05373021987323608]\n",
    "}\n",
    "\n",
    "print(\"\\n三倍資料集(EQ, E0, 0Q)-good&ugly\")\n",
    "df4 = pd.DataFrame(data4, index=['svm', 'rf', 'nn'])\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec4671-dce4-40bb-b886-da8adc8e667e",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a88988-23a9-4859-9f0c-9dabb4334655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gu_cnn_nn_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "# CASE I: 訓練資料是 good=1 & bad=0\n",
    "'''\n",
    "# probability: 儲存原始資料集的 encoder + nn model\n",
    "encoder.save('gb_prob_encoder_model.keras')\n",
    "joblib.dump(nn_model, 'gb_prob_nn_model.pkl')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# multi-hot: 儲存原始資料集 encoder + nn model\n",
    "encoder.save('gb_multihot_encoder_model.keras')\n",
    "joblib.dump(nn_model, 'gb_multihot_nn_model.pkl')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# cnn: 儲存三倍資料集 encoder + svm model\n",
    "encoder.save('gb_cnn_encoder_model.keras')\n",
    "joblib.dump(svm_model, 'gb_cnn_svm_model.pkl')\n",
    "'''\n",
    "\n",
    "# CASE II: 訓練資料是 good=1 & ugly=0\n",
    "'''\n",
    "# probability: 儲存三倍資料集的 autoencoder, encoder + rf model\n",
    "#autoencoder.save('autoencoder_model_prob3.keras')\n",
    "encoder.save('gu_prob_encoder_model.keras')\n",
    "joblib.dump(rf_model, 'gu_prob_rf_model.pkl')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# multi-hot: 儲存原始資料集 autoencoder, encoder + svm model\n",
    "#autoencoder.save('autoencoder_model_multihot.keras')\n",
    "encoder.save('gu_multihot_encoder_model.keras')\n",
    "joblib.dump(svm_model, 'gu_multihot_svm_model.pkl')\n",
    "'''\n",
    "\n",
    "\n",
    "# cnn: 儲存三倍資料集 encoder + nn model\n",
    "encoder.save('gu_cnn_encoder_model.keras')\n",
    "joblib.dump(rf_model, 'gu_cnn_nn_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbff5f-8f9e-4a4e-bae0-7f95a4af7da4",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
