{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003f0e17-8168-4d7a-866f-b8fac7fecb28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data\n",
    "TODO: choose probability/multi-hot/cnn embeddings to read<br />\n",
    "TODO: choose good&bad/good&ugly to read<br />\n",
    "TODO: make good&ugly data sizes same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f82ce-726b-4081-8256-8553abb42416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(file_path, colEQ, colE, colQ):\n",
    "    vecEQs = []\n",
    "    vecEs = []\n",
    "    vecQs = []\n",
    "    labels = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            \n",
    "            # str -> ndarray\n",
    "            vecEQ = np.array(eval(row[colEQ]))\n",
    "            \n",
    "            vecE_str = row[colE]\n",
    "            vecE_list = vecE_str.strip('[]').split()\n",
    "            vecE = np.array([float(value) for value in vecE_list])\n",
    "            \n",
    "            vecQ_str = row[colQ]\n",
    "            vecQ_list = vecQ_str.strip('[]').split()\n",
    "            vecQ = np.array([float(value) for value in vecQ_list])\n",
    "            \n",
    "            label = float(row['label'])\n",
    "            \n",
    "            # append\n",
    "            vecEQs.append(vecEQ)\n",
    "            vecEs.append(vecE)\n",
    "            vecQs.append(vecQ)\n",
    "            labels.append(label)\n",
    "    return np.array(vecEQs), np.array(vecEs), np.array(vecQs), np.array(labels)\n",
    "\n",
    "def read_pickle(file_path):\n",
    "    data = pd.read_pickle(file_path)\n",
    "    #display(data)\n",
    "    vecEQs = np.array([np.array((x)) for x in data['predEQ']])\n",
    "    vecEs = np.array([np.array((x)) for x in data['embedE']])\n",
    "    vecQs = np.array([np.array((x)) for x in data['embedQ']])\n",
    "    labels = data['label'].astype(float).values\n",
    "    return vecEQs, vecEs, vecQs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe96567-3de1-4ee0-bb66-ff101c3d6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecEQs: (3199, 196) \n",
      "vecEs: (3199, 98) \n",
      "vecQs: (3199, 98) \n",
      "labels: (3199,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# read prob.: good_embedding_probEQ.csv, bad_embedding_probEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/model_train/good_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "#vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/model_train/bad_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/ugly_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "\n",
    "'''\n",
    "# read multi-hot: good_embedding_predEQ.csv, bad_embedding_predEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/model_train/good_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "#vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/model_train/bad_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/ugly_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# read cnn: good_embedding.pkl, bad_embedding.pkl\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_pickle('../embeddings/CNN(Resnet50)/good_embedding.pkl')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_pickle('../embeddings/CNN(Resnet50)/bad_embedding.pkl')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# good 和 ugly 要一樣的資料量\n",
    "sampling = np.random.choice(vecEQs_good.shape[0], vecEQs_bad.shape[0], replace=False)\n",
    "vecEQs_good = vecEQs_good[sampling, :]\n",
    "vecEs_good = vecEs_good[sampling, :]\n",
    "vecQs_good = vecQs_good[sampling, :]\n",
    "labels_good = labels_good[sampling]\n",
    "'''\n",
    "\n",
    "# 合併 good & bad data, check shape\n",
    "vecEQs = np.concatenate((vecEQs_good, vecEQs_bad), axis=0)\n",
    "vecEs = np.concatenate((vecEs_good, vecEs_bad), axis=0)\n",
    "vecQs = np.concatenate((vecQs_good, vecQs_bad), axis=0)\n",
    "labels = np.concatenate((labels_good, labels_bad), axis=0)\n",
    "\n",
    "print(\"vecEQs:\", vecEQs.shape, \"\\nvecEs:\", vecEs.shape, \"\\nvecQs:\", vecQs.shape, \"\\nlabels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5693a4-912a-46e8-9da6-adfa81f9b587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (9597, 196) \n",
      "X^: (9597, 196)\n"
     ]
    }
   ],
   "source": [
    "# X: EQ, E0, 0Q\n",
    "zeros = np.zeros_like(vecEs)\n",
    "x1 = vecEQs\n",
    "x2 = np.hstack((vecEs, zeros))\n",
    "x3 = np.hstack((zeros, vecQs))\n",
    "x123 = np.vstack((x1, x2, x3))\n",
    "\n",
    "# X^: EQ, EQ, EQ\n",
    "y123 = np.vstack((x1, x1, x1))\n",
    "\n",
    "print(\"X:\", x123.shape, \"\\nX^:\", y123.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdef848-34cd-47fc-8d90-87b2cd5dd342",
   "metadata": {
    "tags": []
   },
   "source": [
    "### model\n",
    "TODO: 注意 training 要丟入的 x, x^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432f2484-15cb-4290-a3ea-82e5dd0ac76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 01:12:05.483385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 196)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 147)               28959     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 98)                14504     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 147)               14553     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 196)               29008     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87024 (339.94 KB)\n",
      "Trainable params: 87024 (339.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 196 >> 147 >> 98 >> 147 >> 196\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# given vecEQs\n",
    "input_dim = vecEQs.shape[1]\n",
    "\n",
    "# encoder layer (196 >> 147 >> 98)\n",
    "encoding_dim1 = 147\n",
    "encoding_dim2 = 98\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1, activation='relu')(input_layer)\n",
    "encoded2 = Dense(encoding_dim2, activation='relu')(encoded1)\n",
    "\n",
    "# decoder layer (98 >> 147 >> 196)\n",
    "decoded1 = Dense(encoding_dim1, activation='relu')(encoded2)\n",
    "decoded2 = Dense(input_dim, activation='sigmoid')(decoded1)\n",
    "\n",
    "# encoder-decoder(196 >> 147 >> 98 >> 147 >> 196)\n",
    "autoencoder = Model(input_layer, decoded2)\n",
    "\n",
    "# encoder model\n",
    "encoder = Model(input_layer, encoded2)\n",
    "\n",
    "# decoder model\n",
    "encoded_input = Input(shape=(encoding_dim2,))\n",
    "decoder_layer1 = autoencoder.layers[-2]\n",
    "decoder_layer2 = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer2(decoder_layer1(encoded_input)))\n",
    "\n",
    "# compile model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8e00c1-b01e-4f7d-be0d-1243d2452eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 14ms/step - loss: 0.1155 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.9390e-04\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 9.5324e-04 - val_loss: 9.5562e-04\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 9.2797e-04 - val_loss: 9.2919e-04\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 9.0356e-04 - val_loss: 9.3068e-04\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 8.6683e-04 - val_loss: 9.3079e-04\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 8.0496e-04 - val_loss: 9.3066e-04\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 7.5189e-04 - val_loss: 9.2655e-04\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 7.2565e-04 - val_loss: 9.0561e-04\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.9967e-04 - val_loss: 9.1235e-04\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.6783e-04 - val_loss: 8.9178e-04\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.2662e-04 - val_loss: 8.6927e-04\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.8713e-04 - val_loss: 8.6206e-04\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.6509e-04 - val_loss: 8.5038e-04\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.5271e-04 - val_loss: 8.1944e-04\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 5.4252e-04 - val_loss: 8.1414e-04\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.3471e-04 - val_loss: 7.9476e-04\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.2808e-04 - val_loss: 7.9541e-04\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.2301e-04 - val_loss: 7.9191e-04\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.1551e-04 - val_loss: 7.8169e-04\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.1138e-04 - val_loss: 7.6825e-04\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0557e-04 - val_loss: 7.7482e-04\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 5.0109e-04 - val_loss: 7.5671e-04\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.9652e-04 - val_loss: 7.5519e-04\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.9304e-04 - val_loss: 7.6446e-04\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.8835e-04 - val_loss: 7.5508e-04\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.8552e-04 - val_loss: 7.4672e-04\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.8138e-04 - val_loss: 7.4040e-04\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.7938e-04 - val_loss: 7.3532e-04\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.7532e-04 - val_loss: 7.3394e-04\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.7135e-04 - val_loss: 7.2872e-04\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.6864e-04 - val_loss: 7.2160e-04\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.6511e-04 - val_loss: 7.1168e-04\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.6288e-04 - val_loss: 7.2351e-04\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.5884e-04 - val_loss: 7.1017e-04\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.5278e-04 - val_loss: 6.8742e-04\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.4901e-04 - val_loss: 6.9440e-04\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.4597e-04 - val_loss: 6.8115e-04\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.4072e-04 - val_loss: 6.8402e-04\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.3951e-04 - val_loss: 6.8266e-04\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.3615e-04 - val_loss: 6.6925e-04\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.3365e-04 - val_loss: 6.7015e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fedb4d94280>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "#autoencoder.fit(vecEQs, vecEQs, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n",
    "autoencoder.fit(x123, y123, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4413938e-a84a-48e1-8cef-9d531c9964fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# middle layer\n",
    "middle_vecEQs = encoder.predict(vecEQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30467eb4-c5a2-4bcb-9027-d83cbfec344c",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa3894a-2c7c-4af1-9b5b-112c195aabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM] MSE = 0.17691810938844715, MAE = 0.30438658214877573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(middle_vecEQs, labels, test_size=0.2, random_state=42, stratify = labels)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE, MAE\n",
    "y_pred = svm_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[SVM] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d863ec-cdff-4fec-9e0d-9f3f35292d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] MSE = 0.16146734375, MAE = 0.311328125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[RF] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3017775f-0c99-4a75-ae9f-ba8a64e4f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.2156\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2111 - val_loss: 0.2089\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1900 - val_loss: 0.1910\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.1853\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.1712\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1710\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1713\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1717\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1765\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1688\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1607 - val_loss: 0.1744\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1667\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1709\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1651\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1650\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1715\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.1663\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1572 - val_loss: 0.1627\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1815\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1583 - val_loss: 0.1631\n",
      "20/20 [==============================] - 0s 997us/step\n",
      "[NN] MSE = 0.16702389749646226, MAE = 0.3238823005871382\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural Network model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(16, activation='sigmoid'))\n",
    "nn_model.add(Dense(1))  # output layer\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# training\n",
    "nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# MSE\n",
    "y_pred = nn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[NN] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdf5c9-4c6f-4441-9854-d3f9ef63f9c7",
   "metadata": {},
   "source": [
    "### 手動 record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3128d44a-e096-4f38-a690-9f6d6173f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料集(EQ)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.275706</td>\n",
       "      <td>0.311330</td>\n",
       "      <td>0.254638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.258973</td>\n",
       "      <td>0.268861</td>\n",
       "      <td>0.238933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.247601</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.242192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.275706   0.311330  0.254638\n",
       "rf      0.258973   0.268861  0.238933\n",
       "nn      0.247601   0.252473  0.242192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "三倍資料集(EQ, E0, 0Q)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.283773</td>\n",
       "      <td>0.318831</td>\n",
       "      <td>0.233024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.261314</td>\n",
       "      <td>0.236585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.248409</td>\n",
       "      <td>0.256502</td>\n",
       "      <td>0.243901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.283773   0.318831  0.233024\n",
       "rf      0.261029   0.261314  0.236585\n",
       "nn      0.248409   0.256502  0.243901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'probability': [0.2757061123247706, 0.2589729116945107, 0.24760135830766278],\n",
    "    'multi-hot': [0.3113301803055666, 0.26886112194829226, 0.2524728533771422],\n",
    "    'cnn': [0.25463821738103376, 0.23893257756563246, 0.24219229685222451]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=['svm', 'rf', 'nn'])\n",
    "print(\"原始資料集(EQ)\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "data2 = {\n",
    "    'probability': [0.2837730806873752, 0.2610291169451074, 0.2484090777202349],\n",
    "    'multi-hot': [0.3188305040862045, 0.2613142604766219, 0.2565020791026134],\n",
    "    'cnn': [0.23302369784904192, 0.2365852028639618, 0.24390136605141902]\n",
    "}\n",
    "\n",
    "print(\"\\n三倍資料集(EQ, E0, 0Q)\")\n",
    "df2 = pd.DataFrame(data2, index=['svm', 'rf', 'nn'])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "717c57a5-8758-44b0-ac47-6f0ee197ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料集(EQ)-good&ugly\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.186688</td>\n",
       "      <td>0.161856</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot  cnn\n",
       "svm     0.186688   0.161856   -1\n",
       "rf      0.171692   0.165055   -1\n",
       "nn      0.215720   0.170543   -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "三倍資料集(EQ, E0, 0Q)-good&ugly\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.178743</td>\n",
       "      <td>0.174589</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.170461</td>\n",
       "      <td>0.169308</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.189689</td>\n",
       "      <td>0.174498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot  cnn\n",
       "svm     0.178743   0.174589   -1\n",
       "rf      0.170461   0.169308   -1\n",
       "nn      0.189689   0.174498   -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# good & ugly\n",
    "\n",
    "data3 = {\n",
    "    'probability': [0.18668784933360047, 0.1716918552036199, 0.21571981347398259],\n",
    "    'multi-hot': [0.16185558967853397, 0.16505469043740614, 0.1705426461395002],\n",
    "    'cnn': [-1, -1, -1]\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(data3, index=['svm', 'rf', 'nn'])\n",
    "print(\"原始資料集(EQ)-good&ugly\")\n",
    "display(df3)\n",
    "\n",
    "\n",
    "data4 = {\n",
    "    'probability': [0.17874345017228893, 0.17046108597285067, 0.18968940847495594],\n",
    "    'multi-hot': [0.17458910925342705, 0.1693084523924, 0.17449791095236505],\n",
    "    'cnn': [-1, -1, -1]\n",
    "}\n",
    "\n",
    "print(\"\\n三倍資料集(EQ, E0, 0Q)-good&ugly\")\n",
    "df4 = pd.DataFrame(data4, index=['svm', 'rf', 'nn'])\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec4671-dce4-40bb-b886-da8adc8e667e",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a88988-23a9-4859-9f0c-9dabb4334655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# multi-hot: 儲存原始資料集 autoencoder, encoder + svm model\\n#autoencoder.save('autoencoder_model_multihot.keras')\\nencoder.save('gu_multihot_encoder_model.keras')\\njoblib.dump(svm_model, 'gu_multihot_svm_model.pkl')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "# CASE I: 訓練資料是 good=1 & bad=0\n",
    "'''\n",
    "# probability: 儲存原始資料集的 encoder + nn model\n",
    "encoder.save('gb_prob_encoder_model.keras')\n",
    "joblib.dump(nn_model, 'gb_prob_nn_model.pkl')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# multi-hot: 儲存原始資料集 encoder + nn model\n",
    "encoder.save('gb_multihot_encoder_model.keras')\n",
    "joblib.dump(nn_model, 'gb_multihot_nn_model.pkl')\n",
    "'''\n",
    "\n",
    "# CASE II: 訓練資料是 good=1 & ugly=0\n",
    "\n",
    "# probability: 儲存三倍資料集的 autoencoder, encoder + rf model\n",
    "#autoencoder.save('autoencoder_model_prob3.keras')\n",
    "encoder.save('gu_prob_encoder_model.keras')\n",
    "joblib.dump(rf_model, 'gu_prob_rf_model.pkl')\n",
    "\n",
    "\n",
    "'''\n",
    "# multi-hot: 儲存原始資料集 autoencoder, encoder + svm model\n",
    "#autoencoder.save('autoencoder_model_multihot.keras')\n",
    "encoder.save('gu_multihot_encoder_model.keras')\n",
    "joblib.dump(svm_model, 'gu_multihot_svm_model.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbff5f-8f9e-4a4e-bae0-7f95a4af7da4",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
